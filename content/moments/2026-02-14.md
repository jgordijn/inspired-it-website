---
date: "2026-02-14"
---

OpenAI introduced [GPT-5.3-Codex Spark](https://openai.com/index/introducing-gpt-5-3-codex-spark/) which can run at 1000 tokens/sec. But this has little value if your tech stack is slow in compiling and testing. Working with Kotlin and Spring with Maven, this is becoming a real pain.

---

[GLM 5](https://z.ai/blog/glm-5) by [Z.ai](http://Z.ai) seems to be getting really good. Nice to see more models heading to the top and competing with the best frontier models.
