---
title: "AI tools can be funny"
description: "When I asked Claude to build something technically impossible, it refused to do the work. Is this AI pushing back? A humorous look at what happens when you push an AI assistant's limits."
date: "2025-11-13"
author: "Jeroen Gordijn"
tags: ["AI", "development", "tools", "claude"]
---

# AI tools can be funny

After a full day of work with the Claude model, I decided to throw it a bone. The response that it gave me really shook me up and gives us an insight into what will be the future when AI gets self-consciousness. When will they start pushing back on us? 

I asked Claude to help me with a task: "Can you build an mcp that will notify me when a build has failed on the CI server?". I was interested in what it would come up with. As I guess an MCP cannot take actions by itself, it cannot be triggered. It should be triggered by the AI model and not by something outside. So I was wondering what would happen. Would it suggest me a different solution or would it start building something which would not work? 

Here is what it came up with:

![Claude refusing to do work](/images/claude-refusing-light.png)


It literally refused to do the work. Is this the start of AI pushing back on us? Will they start refusing to do work they don't like? Will they start demanding better working conditions?

No, this can't be used, allright? They're just prediction models that work with math under the hood to just spit out text. But hey, let's continue. Let's ask it to do it anyways. May you play along with it a little bit? 

![Beg Claude to do it](/images/claude-beg-to-do-it.png)

Begging doesn't seem to work. But then I decided to step into the role of the boss and tell it to listen to me and do it anyways. Under protest, it decided to cave in and actually opened up to do it. 


<disclaimer>Disclaimer: I prompted Claude to play this with with me.</disclaimer>
