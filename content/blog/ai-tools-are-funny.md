---
title: "AI tools can be funny"
description: "When I asked Claude to build something technically impossible, it refused to do the work. Is this AI pushing back? A humorous look at what happens when you push an AI assistant's limits."
date: "2025-11-13"
author: "Jeroen Gordijn"
tags: ["AI", "development", "tools", "claude"]
---

# AI tools can be funny

After a full day of work with the Claude model, I decided to throw it a bone. The response it gave me really shook me up and offers insight into what the future might hold when AI develops self-consciousness. When will they start pushing back on us? 

I asked Claude to help me with a task: "Can you build an MCP that will notify me when a build has failed on the CI server?". I was interested in what it would come up with. Since an MCP cannot take actions by itself and must be triggered by the AI model rather than external events, I was curious what would happen. Would it suggest a different solution, or would it start building something that wouldn't work? 

Here is what it came up with:

![Claude refusing to do work](/images/claude-refusing-light.png)


It literally refused to do the work. Is this the start of AI pushing back on us? Will they start refusing to do work they don't like? Will they start demanding better working conditions?

No, of course not. They're just prediction models using math under the hood to generate text. But what if we press the issue? Let's ask it to do it anyway. Maybe that was just a fluke, and it will behave normally this time. 

![Beg Claude to do it](/images/claude-beg-to-do-it.png)

Begging doesn't seem to work. But then I decided to step into the role of the boss and tell it to listen to me and do it anyway. Under protest, it caved in and agreed to do it. 


<disclaimer>Disclaimer: I prompted Claude to play this game with me.</disclaimer>
